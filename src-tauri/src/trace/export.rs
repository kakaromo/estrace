use std::fs::File;
use std::path::PathBuf;

use arrow::array::{RecordBatchWriter, Float64Array, Array};
use arrow::datatypes::DataType;
use datafusion::arrow::csv::WriterBuilder;
use datafusion::prelude::*; // RecordBatchWriter íŠ¸ë ˆì´íŠ¸ ì¶”ê°€
use serde::Deserialize;

// Excelì˜ ìµœëŒ€ í–‰ ìˆ˜ (í—¤ë” ì œì™¸)
const EXCEL_MAX_ROWS: usize = 1_048_575;

// í•„í„° íŒŒë¼ë¯¸í„° êµ¬ì¡°ì²´
#[derive(Debug, Deserialize)]
pub struct FilterParams {
    pub time_from: Option<f64>,
    pub time_to: Option<f64>,
    pub zoom_column: Option<String>,  // "lba" or "sector"
    pub col_from: Option<f64>,
    pub col_to: Option<f64>,
}

// CSV ë‚´ë³´ë‚´ê¸° ê³µí†µ í•¨ìˆ˜ (í•„í„° ì§€ì›)
pub async fn export_to_csv(
    parquet_path: String,
    output_dir: Option<String>,
    filter: Option<FilterParams>,
) -> Result<Vec<String>, String> {
    // DataFusion ì„¸ì…˜ ì´ˆê¸°í™”
    let ctx = SessionContext::new();

    // Parquet íŒŒì¼ ì½ê¸°
    let mut df = ctx
        .read_parquet(parquet_path.as_str(), ParquetReadOptions::default())
        .await
        .map_err(|e| e.to_string())?;

    // í•„í„° ì ìš©
    if let Some(filter_params) = filter {
        println!("ğŸ“Š [Export] í•„í„° ì ìš© ì¤‘...");
        
        // ì‹œê°„ í•„í„° ì ìš©
        if let (Some(t_from), Some(t_to)) = (filter_params.time_from, filter_params.time_to) {
            if t_from > 0.0 || t_to > 0.0 {
                let schema = df.schema();
                let time_column = if schema.fields().iter().any(|f| f.name() == "start_time") {
                    "start_time"
                } else {
                    "time"
                };
                
                df = df
                    .filter(col(time_column).gt_eq(lit(t_from)).and(col(time_column).lt_eq(lit(t_to))))
                    .map_err(|e| e.to_string())?;
                
                println!("â±ï¸  [Export] ì‹œê°„ í•„í„°: {} ~ {}", t_from, t_to);
            }
        }
        
        // LBA/Sector í•„í„° ì ìš©
        if let (Some(zoom_col), Some(c_from), Some(c_to)) = 
            (filter_params.zoom_column.as_ref(), filter_params.col_from, filter_params.col_to) {
            if c_from > 0.0 || c_to > 0.0 {
                df = df
                    .filter(col(zoom_col.as_str()).gt_eq(lit(c_from as i64)).and(col(zoom_col.as_str()).lt_eq(lit(c_to as i64))))
                    .map_err(|e| e.to_string())?;
                
                println!("ğŸ“ [Export] {} í•„í„°: {} ~ {}", zoom_col, c_from, c_to);
            }
        }
    }

    // ìŠ¤í‚¤ë§ˆì—ì„œ ì‹œê°„ ì»¬ëŸ¼ ì´ë¦„ ê²°ì • (start_time ë˜ëŠ” time)
    let schema = df.schema();
    let time_column = if schema.fields().iter().any(|f| f.name() == "start_time") {
        "start_time"
    } else {
        "time"
    };

    // ì‹œê°„ ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬ (ufscustomì€ start_time, ë‚˜ë¨¸ì§€ëŠ” timeìœ¼ë¡œ ì •ë ¬)
    let sorted_df = df
        .sort(vec![col(time_column).sort(true, true)])
        .map_err(|e| e.to_string())?;

    // ë°ì´í„°í”„ë ˆì„ì—ì„œ ë ˆì½”ë“œ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
    let batches = sorted_df.collect().await.map_err(|e| e.to_string())?;

    // ì´ í–‰ ìˆ˜ ê³„ì‚° (ë¡œê¹…ìš©)
    let _total_rows: usize = batches.iter().map(|batch| batch.num_rows()).sum();

    // ì¶œë ¥ íŒŒì¼ ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    let (base_dir, base_filename) = if let Some(dir) = output_dir {
        let input_path = PathBuf::from(&parquet_path);
        let filename = input_path
            .file_stem()
            .ok_or("Invalid parquet path")?
            .to_string_lossy();
        (PathBuf::from(dir), filename.to_string())
    } else {
        let input_path = PathBuf::from(&parquet_path);
        let parent = input_path.parent().ok_or("Invalid parquet path")?;
        let filename = input_path
            .file_stem()
            .ok_or("Invalid parquet path")?
            .to_string_lossy();
        (PathBuf::from(parent), filename.to_string())
    };

    let mut output_paths = Vec::new();
    
    // ì‹œê°„ ê°’ ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜
    let get_time_value = |batch: &arrow::record_batch::RecordBatch, row_index: usize| -> Option<f64> {
        let schema = batch.schema();
        let time_col_index = schema.column_with_name(time_column)?.0;
        let time_array = batch.column(time_col_index);
        
        if let DataType::Float64 = time_array.data_type() {
            let float_array = time_array.as_any().downcast_ref::<Float64Array>()?;
            if row_index < float_array.len() && !float_array.is_null(row_index) {
                return Some(float_array.value(row_index));
            }
        }
        None
    };

    // ì²­í¬ë³„ë¡œ ë°°ì¹˜ë¥¼ ë©”ëª¨ë¦¬ì— ëª¨ì•„ë‘˜ ë²¡í„°
    let mut current_chunk_batches: Vec<arrow::record_batch::RecordBatch> = Vec::new();
    let mut current_row_count = 0;
    let mut chunk_start_time: Option<f64> = None;
    let mut chunk_end_time: Option<f64> = None;

    // ê° ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ë©´ì„œ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• 
    for batch in batches {
        let batch_rows = batch.num_rows();
        let mut batch_offset = 0;

        while batch_offset < batch_rows {
            // í˜„ì¬ ì²­í¬ì— ì¶”ê°€ ê°€ëŠ¥í•œ í–‰ ìˆ˜ ê³„ì‚°
            let remaining_capacity = EXCEL_MAX_ROWS - current_row_count;
            let rows_to_write = std::cmp::min(remaining_capacity, batch_rows - batch_offset);

            // ë°°ì¹˜ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ìŠ¬ë¼ì´ìŠ¤
            let slice_batch = if rows_to_write == batch_rows && batch_offset == 0 {
                batch.clone()
            } else {
                batch.slice(batch_offset, rows_to_write)
            };

            // ì²­í¬ì˜ ì‹œì‘ ì‹œê°„ ì„¤ì • (ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì²« ë²ˆì§¸ í–‰)
            if chunk_start_time.is_none() && slice_batch.num_rows() > 0 {
                chunk_start_time = get_time_value(&slice_batch, 0);
            }
            
            // ì²­í¬ì˜ ë ì‹œê°„ ê°±ì‹  (ë§ˆì§€ë§‰ ë°°ì¹˜ì˜ ë§ˆì§€ë§‰ í–‰)
            if slice_batch.num_rows() > 0 {
                chunk_end_time = get_time_value(&slice_batch, slice_batch.num_rows() - 1);
            }

            // ë©”ëª¨ë¦¬ì— ë°°ì¹˜ ì¶”ê°€
            current_chunk_batches.push(slice_batch);
            current_row_count += rows_to_write;
            batch_offset += rows_to_write;

            // ì²­í¬ê°€ ê°€ë“ ì°¼ê±°ë‚˜ ë§ˆì§€ë§‰ ë°°ì¹˜ì¸ ê²½ìš° íŒŒì¼ë¡œ ì €ì¥
            if current_row_count >= EXCEL_MAX_ROWS {
                // íŒŒì¼ëª… ìƒì„± (ì‹œì‘ ì‹œê°„ì´ ë ì‹œê°„ë³´ë‹¤ ì‘ë„ë¡ ë³´ì¥)
                let (start, end) = match (chunk_start_time, chunk_end_time) {
                    (Some(s), Some(e)) if s <= e => (s, e),
                    (Some(s), Some(e)) => (e, s),
                    _ => (0.0, 0.0),
                };
                
                let final_filename = format!("{}_{:.3}_{:.3}.csv", base_filename, start, end);
                let mut final_path = base_dir.clone();
                final_path.push(&final_filename);
                
                // íŒŒì¼ ìƒì„± ë° í•œ ë²ˆì— ì“°ê¸°
                let file = File::create(&final_path).map_err(|e| e.to_string())?;
                let mut writer = WriterBuilder::new().with_header(true).build(file);
                
                for chunk_batch in &current_chunk_batches {
                    writer.write(chunk_batch).map_err(|e| e.to_string())?;
                }
                
                writer.close().map_err(|e| e.to_string())?;
                output_paths.push(final_path.to_string_lossy().to_string());
                
                // ë‹¤ìŒ ì²­í¬ë¥¼ ìœ„í•´ ì´ˆê¸°í™”
                current_chunk_batches.clear();
                current_row_count = 0;
                chunk_start_time = None;
                chunk_end_time = None;
            }
        }
    }

    // ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
    if !current_chunk_batches.is_empty() {
        // ë§ˆì§€ë§‰ ì²­í¬ì˜ ì‹¤ì œ ì‹œì‘/ë ì‹œê°„ì„ ë°°ì¹˜ë“¤ë¡œë¶€í„° ë‹¤ì‹œ ê³„ì‚°
        let last_chunk_start = current_chunk_batches.first()
            .and_then(|batch| if batch.num_rows() > 0 { get_time_value(batch, 0) } else { None });

        let last_chunk_end = current_chunk_batches.last()
            .and_then(|batch| {
                let num_rows = batch.num_rows();
                if num_rows > 0 {
                    get_time_value(batch, num_rows - 1)
                } else {
                    None
                }
            });

        // íŒŒì¼ëª… ìƒì„± (ì‹œì‘ ì‹œê°„ì´ ë ì‹œê°„ë³´ë‹¤ ì‘ë„ë¡ ë³´ì¥)
        let (start, end) = match (last_chunk_start, last_chunk_end) {
            (Some(s), Some(e)) if s <= e => (s, e),
            (Some(s), Some(e)) => (e, s),
            _ => (0.0, 0.0),
        };

        let final_filename = format!("{}_{:.3}_{:.3}.csv", base_filename, start, end);
        let mut final_path = base_dir.clone();
        final_path.push(&final_filename);

        // íŒŒì¼ ìƒì„± ë° í•œ ë²ˆì— ì“°ê¸°
        let file = File::create(&final_path).map_err(|e| e.to_string())?;
        let mut writer = WriterBuilder::new().with_header(true).build(file);

        for chunk_batch in &current_chunk_batches {
            writer.write(chunk_batch).map_err(|e| e.to_string())?;
        }

        writer.close().map_err(|e| e.to_string())?;
        output_paths.push(final_path.to_string_lossy().to_string());
    }

    Ok(output_paths)
}