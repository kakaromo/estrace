use std::collections::{BTreeMap, HashMap};
use std::fs::{create_dir_all, File};
use std::path::PathBuf;
use std::sync::Arc;

use arrow::array::{ArrayRef, BooleanArray, Float64Array, StringArray, UInt32Array, UInt64Array};
use arrow::datatypes::{DataType, Field, Schema};
use arrow::record_batch::RecordBatch;
use parquet::arrow::ArrowWriter;
use tauri::Emitter;


use crate::trace::filter::{filter_ufscustom_data};
use crate::trace::utils::{
    calculate_statistics, create_range_key, initialize_ranges, parse_time_to_ms,
};
use crate::trace::{
    ContinuityCount, ContinuityStats, LatencyStat, LatencyStats, LatencyValue, SizeStats,
    TotalContinuity, TraceStats, UFSCUSTOM,
};

const MILLISECONDS_CONST: u32 = 1000;

// UFSCUSTOM ë ˆì´í„´ì‹œ í›„ì²˜ë¦¬ í•¨ìˆ˜
pub fn ufscustom_bottom_half_latency_process(mut ufscustom_list: Vec<UFSCUSTOM>) -> Vec<UFSCUSTOM> {
    // ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë²¡í„° ë°˜í™˜
    if ufscustom_list.is_empty() {
        return ufscustom_list;
    }

    // ì‹œì‘ ì‹œê°„ ê¸°ë¡
    let start_time = std::time::Instant::now();
    println!("\nğŸ”„ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ“Š UFSCUSTOM Latency í›„ì²˜ë¦¬ ì‹œì‘");
    println!("   ì´ ì´ë²¤íŠ¸ ìˆ˜: {}", ufscustom_list.len());
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    
    // ì •ë ¬ ì—¬ë¶€ í™•ì¸ (ì´ë¯¸ ì •ë ¬ë˜ì–´ ìˆìœ¼ë©´ ì •ë ¬ ìŠ¤í‚µ)
    println!("\n[1/3] â±ï¸  ë°ì´í„° ìˆœì„œ í™•ì¸ ì¤‘...");
    let sort_start = std::time::Instant::now();
    let mut needs_sort = false;
    for i in 1..ufscustom_list.len().min(1000) {
        if ufscustom_list[i - 1].start_time > ufscustom_list[i].start_time {
            needs_sort = true;
            break;
        }
    }
    
    let sort_elapsed = if needs_sort {
        println!("      âš ï¸  ì •ë ¬ë˜ì§€ ì•Šì€ ë°ì´í„° ê°ì§€, ì •ë ¬ ì¤‘...");
        ufscustom_list.sort_unstable_by(|a, b| {
            a.start_time.partial_cmp(&b.start_time).unwrap_or(std::cmp::Ordering::Equal)
        });
        let elapsed = sort_start.elapsed().as_secs_f64();
        println!("      âœ… ì •ë ¬ ì™„ë£Œ: {:.2}ì´ˆ", elapsed);
        elapsed
    } else {
        let elapsed = sort_start.elapsed().as_secs_f64();
        println!("      âœ… ì´ë¯¸ ì •ë ¬ë¨ (ì •ë ¬ ìŠ¤í‚µ): {:.3}ì´ˆ", elapsed);
        elapsed
    };

    // ì´ë²¤íŠ¸ ê¸°ë°˜ QD ê³„ì‚°ì„ ìœ„í•œ êµ¬ì¡°ì²´
    #[derive(Debug, Clone, Copy)]
    struct Event {
        time: f64,
        event_type: EventType,
        request_idx: usize,
    }

    #[derive(Debug, Clone, Copy, PartialEq)]
    enum EventType {
        Start,
        Complete,
    }

    // ëª¨ë“  ìš”ì²­ì— ëŒ€í•œ ì´ë²¤íŠ¸ ìƒì„± (ìš©ëŸ‰ ì‚¬ì „ í• ë‹¹)
    println!("\n[2/3] ğŸ”¢ QD ê³„ì‚° ì¤‘...");
    let qd_calc_start = std::time::Instant::now();
    let mut events = Vec::with_capacity(ufscustom_list.len() * 2);
    for (idx, ufscustom) in ufscustom_list.iter().enumerate() {
        events.push(Event {
            time: ufscustom.start_time,
            event_type: EventType::Start,
            request_idx: idx,
        });
        events.push(Event {
            time: ufscustom.end_time,
            event_type: EventType::Complete,
            request_idx: idx,
        });
    }

    // ì‹œê°„ìˆœìœ¼ë¡œ ì´ë²¤íŠ¸ ì •ë ¬ (unstable sort)
    events.sort_unstable_by(|a, b| {
        a.time.partial_cmp(&b.time).unwrap_or(std::cmp::Ordering::Equal)
    });

    // ì´ë²¤íŠ¸ ì²˜ë¦¬í•˜ì—¬ ê° ìš”ì²­ì˜ start_qd, end_qd ê³„ì‚°
    let mut current_qd = 0u32;
    let mut qd_values = vec![(0u32, 0u32); ufscustom_list.len()]; // (start_qd, end_qd)

    for event in &events {
        match event.event_type {
            EventType::Start => {
                current_qd += 1;
                qd_values[event.request_idx].0 = current_qd; // start_qd ì„¤ì • (1ë¶€í„° ì‹œì‘)
            }
            EventType::Complete => {
                current_qd = current_qd.saturating_sub(1);
                qd_values[event.request_idx].1 = current_qd; // end_qd ì„¤ì •
            }
        }
    }

    // ì´ë²¤íŠ¸ ë²¡í„°ëŠ” ìë™ìœ¼ë¡œ ìŠ¤ì½”í”„ ì¢…ë£Œì‹œ í•´ì œë¨
    
    let qd_calc_elapsed = qd_calc_start.elapsed().as_secs_f64();
    println!("      âœ… QD ê³„ì‚° ì™„ë£Œ: {:.2}ì´ˆ", qd_calc_elapsed);

    // QD ê°’ë“¤ì„ ì‹¤ì œ êµ¬ì¡°ì²´ì— ì„¤ì •
    for (idx, ufscustom) in ufscustom_list.iter_mut().enumerate() {
        ufscustom.start_qd = qd_values[idx].0;
        ufscustom.end_qd = qd_values[idx].1;
    }

    // CTOC, CTOD, continuous ê³„ì‚°
    let mut prev_request: Option<(u64, u32, String)> = None;
    let mut last_complete_time: Option<f64> = None;
    let mut last_qd_zero_complete_time: Option<f64> = None; // QDê°€ 0ì´ ë  ë•Œì˜ ì™„ë£Œ ì‹œê°„
    
    let total_items = ufscustom_list.len();
    let report_threshold = total_items / 20; // 5% ê°„ê²©
    
    println!("\n[3/3] âš™ï¸  Latency ë° ì—°ì†ì„± ê³„ì‚° ì¤‘...");
    let latency_start = std::time::Instant::now();

    for (i, ufscustom) in ufscustom_list.iter_mut().enumerate() {
        // ì§„í–‰ë¥  ì¶œë ¥ (5% ê°„ê²©, ëª¨ë“ˆë¡œ ì—°ì‚°)
        if report_threshold > 0 && i % report_threshold == 0 && i > 0 {
            let progress = (i * 100) / total_items;
            let elapsed = latency_start.elapsed().as_secs_f64();
            let rate = i as f64 / elapsed;
            let remaining = total_items - i;
            let eta = if rate > 0.0 { remaining as f64 / rate } else { 0.0 };
            println!("      ğŸ“Œ ì§„í–‰ë¥ : {}% ({}/{}) | ì†ë„: {:.0} events/s | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {:.1}ì´ˆ", 
                     progress, i, total_items, rate, eta);
        }

        // continuous ìš”ì²­ íŒë‹¨
        if let Some((prev_lba, prev_size, ref prev_opcode)) = prev_request {
            ufscustom.continuous = ufscustom.lba == prev_lba + prev_size as u64
                && ufscustom.opcode == *prev_opcode;
        } else {
            ufscustom.continuous = false;
        }

        // CTOC ê³„ì‚° (Complete to Complete) - ì´ì „ ì™„ë£Œì—ì„œ í˜„ì¬ ì™„ë£Œê¹Œì§€
        ufscustom.ctoc = if let Some(prev_complete) = last_complete_time {
            let time_diff = ufscustom.end_time - prev_complete;
            if time_diff >= 0.0 { time_diff * MILLISECONDS_CONST as f64 } else { 0.0 }
        } else {
            0.0 // ì²« ë²ˆì§¸ ìš”ì²­
        };

        // CTOD ê³„ì‚° (Complete to Dispatch)
        // start_qdê°€ 1ì¸ ê²½ìš°: ì´ì „ QD=0 ì™„ë£Œì—ì„œ í˜„ì¬ ì‹œì‘ê¹Œì§€
        // start_qdê°€ 1ì´ ì•„ë‹Œ ê²½ìš°: ì´ì „ ì™„ë£Œì—ì„œ í˜„ì¬ ì‹œì‘ê¹Œì§€
        ufscustom.ctod = if ufscustom.start_qd == 1 {
            if let Some(prev_qd_zero_complete) = last_qd_zero_complete_time {
                let time_diff = ufscustom.start_time - prev_qd_zero_complete;
                if time_diff >= 0.0 { time_diff * MILLISECONDS_CONST as f64 } else { 0.0 }
            } else {
                0.0 // ì²« ë²ˆì§¸ idle ì‹œì‘ ìš”ì²­
            }
        } else if let Some(prev_complete) = last_complete_time {
            let time_diff = ufscustom.start_time - prev_complete;
            if time_diff >= 0.0 { time_diff * MILLISECONDS_CONST as f64 } else { 0.0 }
        } else {
            0.0 // ì²« ë²ˆì§¸ ìš”ì²­
        };

        // ì™„ë£Œ ì‹œê°„ ì—…ë°ì´íŠ¸
        last_complete_time = Some(ufscustom.end_time);
        
        // QDê°€ 0ì´ ë˜ëŠ” ì™„ë£Œ ì‹œê°„ ì—…ë°ì´íŠ¸
        if ufscustom.end_qd == 0 {
            last_qd_zero_complete_time = Some(ufscustom.end_time);
        }

        // í˜„ì¬ ìš”ì²­ ì •ë³´ ì €ì¥
        prev_request = Some((ufscustom.lba, ufscustom.size, ufscustom.opcode.clone()));
    }

    let latency_elapsed = latency_start.elapsed().as_secs_f64();
    let latency_rate = ufscustom_list.len() as f64 / latency_elapsed;
    println!("      âœ… ê³„ì‚° ì™„ë£Œ: {} ì´ë²¤íŠ¸ | {:.2}ì´ˆ | {:.0} events/s", 
             ufscustom_list.len(), latency_elapsed, latency_rate);
    
    // ë©”ëª¨ë¦¬ ìµœì í™”
    ufscustom_list.shrink_to_fit();

    let total_elapsed = start_time.elapsed().as_secs_f64();
    let total_rate = ufscustom_list.len() as f64 / total_elapsed;
    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("âœ¨ UFSCUSTOM Latency í›„ì²˜ë¦¬ ì™„ë£Œ!");
    println!("   ì´ ì†Œìš” ì‹œê°„: {:.2}ì´ˆ", total_elapsed);
    println!("   í‰ê·  ì²˜ë¦¬ ì†ë„: {:.0} events/s", total_rate);
    println!("   ìµœì¢… ì´ë²¤íŠ¸ ìˆ˜: {}", ufscustom_list.len());
    println!("   ë‹¨ê³„ë³„ ì‹œê°„:");
    println!("     - ì •ë ¬: {:.2}ì´ˆ ({:.1}%)", sort_elapsed, (sort_elapsed / total_elapsed) * 100.0);
    println!("     - QD ê³„ì‚°: {:.2}ì´ˆ ({:.1}%)", qd_calc_elapsed, (qd_calc_elapsed / total_elapsed) * 100.0);
    println!("     - Latency ê³„ì‚°: {:.2}ì´ˆ ({:.1}%)", latency_elapsed, (latency_elapsed / total_elapsed) * 100.0);
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");

    ufscustom_list
}

// UFSCUSTOMì„ RecordBatchë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
pub fn ufscustom_to_record_batch(ufscustom_list: &[UFSCUSTOM]) -> Result<RecordBatch, String> {
    // ë¹ˆ ë²¡í„°ì¸ ê²½ìš° ë¹ˆ RecordBatch ë°˜í™˜
    if ufscustom_list.is_empty() {
        let schema = Arc::new(Schema::new(vec![
            Field::new("opcode", DataType::Utf8, false),
            Field::new("lba", DataType::UInt64, false),
            Field::new("size", DataType::UInt32, false),
            Field::new("start_time", DataType::Float64, false),
            Field::new("end_time", DataType::Float64, false),            
            Field::new("start_qd", DataType::UInt32, false),
            Field::new("end_qd", DataType::UInt32, false),
            Field::new("dtoc", DataType::Float64, false),
            Field::new("ctoc", DataType::Float64, false),
            Field::new("ctod", DataType::Float64, false),
            Field::new("continuous", DataType::Boolean, false),
        ]));
        
        let arrays: Vec<ArrayRef> = vec![
            Arc::new(StringArray::from(Vec::<String>::new())),  // opcode
            Arc::new(UInt64Array::from(Vec::<u64>::new())),     // lba
            Arc::new(UInt32Array::from(Vec::<u32>::new())),     // size
            Arc::new(Float64Array::from(Vec::<f64>::new())),    // start_time
            Arc::new(Float64Array::from(Vec::<f64>::new())),    // end_time
            Arc::new(UInt32Array::from(Vec::<u32>::new())),     // start_qd
            Arc::new(UInt32Array::from(Vec::<u32>::new())),     // end_qd
            Arc::new(Float64Array::from(Vec::<f64>::new())),    // dtoc
            Arc::new(Float64Array::from(Vec::<f64>::new())),    // ctoc
            Arc::new(Float64Array::from(Vec::<f64>::new())),    // ctod
            Arc::new(BooleanArray::from(Vec::<bool>::new())),   // continuous
        ];
        
        return RecordBatch::try_new(schema, arrays).map_err(|e| e.to_string());
    }

    // ë²¡í„°ë“¤ì„ ë¯¸ë¦¬ í• ë‹¹
    let len = ufscustom_list.len();
    let mut opcode_vec = Vec::with_capacity(len);
    let mut lba_vec = Vec::with_capacity(len);
    let mut size_vec = Vec::with_capacity(len);
    let mut start_time_vec = Vec::with_capacity(len);
    let mut end_time_vec = Vec::with_capacity(len);    
    let mut start_qd_vec = Vec::with_capacity(len);
    let mut end_qd_vec = Vec::with_capacity(len);
    let mut dtoc_vec = Vec::with_capacity(len);
    let mut ctoc_vec = Vec::with_capacity(len);
    let mut ctod_vec = Vec::with_capacity(len);
    let mut continuous_vec = Vec::with_capacity(len);

    // ë°ì´í„° ë³µì‚¬
    for ufscustom in ufscustom_list {
        opcode_vec.push(ufscustom.opcode.as_str());
        lba_vec.push(ufscustom.lba);
        size_vec.push(ufscustom.size);
        start_time_vec.push(ufscustom.start_time);
        end_time_vec.push(ufscustom.end_time);        
        start_qd_vec.push(ufscustom.start_qd);
        end_qd_vec.push(ufscustom.end_qd);
        dtoc_vec.push(ufscustom.dtoc);
        ctoc_vec.push(ufscustom.ctoc);
        ctod_vec.push(ufscustom.ctod);
        continuous_vec.push(ufscustom.continuous);
    }

    // ìŠ¤í‚¤ë§ˆ ì •ì˜
    let schema = Arc::new(Schema::new(vec![
        Field::new("opcode", DataType::Utf8, false),
        Field::new("lba", DataType::UInt64, false),
        Field::new("size", DataType::UInt32, false),
        Field::new("start_time", DataType::Float64, false),
        Field::new("end_time", DataType::Float64, false),        
        Field::new("start_qd", DataType::UInt32, false),
        Field::new("end_qd", DataType::UInt32, false),
        Field::new("dtoc", DataType::Float64, false),
        Field::new("ctoc", DataType::Float64, false),
        Field::new("ctod", DataType::Float64, false),
        Field::new("continuous", DataType::Boolean, false),
    ]));

    // ArrayRef ë²¡í„° ìƒì„±
    let arrays: Vec<ArrayRef> = vec![
        Arc::new(StringArray::from(opcode_vec)),
        Arc::new(UInt64Array::from(lba_vec)),
        Arc::new(UInt32Array::from(size_vec)),
        Arc::new(Float64Array::from(start_time_vec)),
        Arc::new(Float64Array::from(end_time_vec)),        
        Arc::new(UInt32Array::from(start_qd_vec)),
        Arc::new(UInt32Array::from(end_qd_vec)),
        Arc::new(Float64Array::from(dtoc_vec)),
        Arc::new(Float64Array::from(ctoc_vec)),
        Arc::new(Float64Array::from(ctod_vec)),
        Arc::new(BooleanArray::from(continuous_vec)),
    ];

    RecordBatch::try_new(schema, arrays).map_err(|e| e.to_string())
}

// UFSCUSTOMì„ Parquet íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ - chunk ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ OOM ë°©ì§€
pub fn save_ufscustom_to_parquet(
    ufscustom_list: &[UFSCUSTOM],
    logfolder: String,
    fname: String,
    timestamp: &str,
    window: Option<&tauri::Window>,
) -> Result<String, String> {
    // logfolder ë‚´ì— stem í´ë” ìƒì„±
    let stem = PathBuf::from(&fname)
        .file_stem()
        .ok_or("Invalid filename")?
        .to_string_lossy()
        .to_string();

    let mut folder_path = PathBuf::from(logfolder);
    folder_path.push(&stem);
    create_dir_all(&folder_path).map_err(|e| e.to_string())?;

    let ufscustom_filename = format!("{}_ufscustom.parquet", timestamp);
    let mut path = folder_path;
    path.push(&ufscustom_filename);

    // chunk í¬ê¸° ì„¤ì • (400,000 ë ˆì½”ë“œì”© ì²˜ë¦¬)
    const CHUNK_SIZE: usize = 400_000;
    let total_records = ufscustom_list.len();
    
    if total_records == 0 {
        return Err("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.".to_string());
    }
    
    println!("UFSCUSTOM ë°ì´í„° ì €ì¥ ì‹œì‘: {} ë ˆì½”ë“œë¥¼ {} ë ˆì½”ë“œì”© Chunkë¡œ ì²˜ë¦¬", total_records, CHUNK_SIZE);
    
    let total_chunks = (total_records + CHUNK_SIZE - 1) / CHUNK_SIZE;
    
    // ì²« ë²ˆì§¸ Chunkë¡œ ìŠ¤í‚¤ë§ˆ ìƒì„±
    let first_chunk = if total_records > CHUNK_SIZE {
        &ufscustom_list[0..CHUNK_SIZE]
    } else {
        ufscustom_list
    };
    
    let first_batch = ufscustom_to_record_batch(first_chunk)?;
    let schema = first_batch.schema();
    let file = File::create(&path).map_err(|e| e.to_string())?;
    let mut writer = ArrowWriter::try_new(file, schema.clone(), None).map_err(|e| e.to_string())?;
    
    // ì²« ë²ˆì§¸ Chunk ì“°ê¸°
    writer.write(&first_batch).map_err(|e| e.to_string())?;
    println!("UFSCUSTOM Chunk 1/{} ì €ì¥ ì™„ë£Œ", total_chunks);
    
    // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì²« ë²ˆì§¸ Chunk)
    if let Some(w) = window {
        let progress = 85.0 + (1.0 / total_chunks as f64) * 10.0; // 85%ì—ì„œ 95% ì‚¬ì´
        let _ = w.emit("trace-progress", crate::trace::ProgressEvent {
            stage: "saving".to_string(),
            progress: progress as f32,
            current: (85 + ((1 * 10) / total_chunks)) as u64,
            total: 100,
            message: format!("UFSCUSTOM Parquet ì €ì¥ ì¤‘: {}/{} Chunk", 1, total_chunks),
            eta_seconds: (total_chunks - 1) as f32 * 0.5,
            processing_speed: 0.0,
        });
    }
    
    // ë‚˜ë¨¸ì§€ Chunkë“¤ ì²˜ë¦¬
    let mut chunk_num = 2;
    for chunk_start in (CHUNK_SIZE..total_records).step_by(CHUNK_SIZE) {
        let chunk_end = std::cmp::min(chunk_start + CHUNK_SIZE, total_records);
        let chunk = &ufscustom_list[chunk_start..chunk_end];
        
        let batch = ufscustom_to_record_batch(chunk)?;
        writer.write(&batch).map_err(|e| e.to_string())?;
        
        println!("UFSCUSTOM Chunk {}/{} ì €ì¥ ì™„ë£Œ", chunk_num, total_chunks);
        
        // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        if let Some(w) = window {
            let progress = 85.0 + (chunk_num as f64 / total_chunks as f64) * 10.0;
            let _ = w.emit("trace-progress", crate::trace::ProgressEvent {
                stage: "saving".to_string(),
                progress: progress as f32,
                current: (85 + ((chunk_num * 10) / total_chunks)) as u64,
                total: 100,
                message: format!("UFSCUSTOM Parquet ì €ì¥ ì¤‘: {}/{} Chunk", chunk_num, total_chunks),
                eta_seconds: (total_chunks - chunk_num) as f32 * 0.5,
                processing_speed: 0.0,
            });
        }
        
        chunk_num += 1;
    }
    
    writer.close().map_err(|e| e.to_string())?;
    println!("UFSCUSTOM Parquet íŒŒì¼ ì €ì¥ ì™„ë£Œ: {}", path.to_string_lossy());

    Ok(path.to_string_lossy().to_string())
}

// UFSCUSTOM ë ˆì´í„´ì‹œ í†µê³„ ë¶„ì„ì„ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ êµ¬ì¡°ì²´
#[derive(Debug, Clone)]
pub struct UfscustomLatencyStatsParams {
    pub logname: String,
    pub column: String,
    pub zoom_column: String,
    pub time_from: Option<f64>,
    pub time_to: Option<f64>,
    pub col_from: Option<f64>,
    pub col_to: Option<f64>,
    pub thresholds: Vec<String>,
}

// UFSCUSTOM í¬ê¸° í†µê³„ ë¶„ì„ì„ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ êµ¬ì¡°ì²´
#[derive(Debug, Clone)]
pub struct UfscustomSizeStatsParams {
    pub logname: String,
    #[allow(dead_code)]
    pub column: String,
    pub zoom_column: String,
    pub time_from: Option<f64>,
    pub time_to: Option<f64>,
    pub col_from: Option<f64>,
    pub col_to: Option<f64>,
}

// UFSCUSTOM ì¢…í•© í†µê³„ ë¶„ì„ì„ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ êµ¬ì¡°ì²´
#[derive(Debug, Clone)]
pub struct UfscustomAllStatsParams {
    pub logname: String,
    pub zoom_column: String,
    pub time_from: Option<f64>,
    pub time_to: Option<f64>,
    pub col_from: Option<f64>,
    pub col_to: Option<f64>,
}

// UFSCUSTOM ë ˆì´í„´ì‹œ í†µê³„ í•¨ìˆ˜
pub async fn latencystats(params: UfscustomLatencyStatsParams) -> Result<Vec<u8>, String> {
    // ë¬¸ìì—´ thresholdsë¥¼ ë°€ë¦¬ì´ˆ ê°’ìœ¼ë¡œ ë³€í™˜
    let mut threshold_values: Vec<f64> = Vec::new();
    for t in &params.thresholds {
        let ms = parse_time_to_ms(t)?;
        threshold_values.push(ms);
    }

    // í•„í„°ë§ ì ìš©
    let filtered_ufscustom =
        filter_ufscustom_data(&params.logname, params.time_from, params.time_to, &params.zoom_column, params.col_from, params.col_to, None)?;

    // LatencyStat ìƒì„± - columnì— ë”°ë¼ ë°ì´í„° ë§¤í•‘
    let latency_stats = match params.column.as_str() {
        "dtoc" => filtered_ufscustom
            .iter()
            .map(|ufscustom| LatencyStat {
                time: ufscustom.start_time,
                opcode: ufscustom.opcode.clone(),
                value: LatencyValue::F64(ufscustom.dtoc),
            })
            .collect::<Vec<_>>(),
        "ctoc" => filtered_ufscustom
            .iter()
            .map(|ufscustom| LatencyStat {
                time: ufscustom.start_time,
                opcode: ufscustom.opcode.clone(),
                value: LatencyValue::F64(ufscustom.ctoc),
            })
            .collect::<Vec<_>>(),
        "ctod" => filtered_ufscustom
            .iter()
            .map(|ufscustom| LatencyStat {
                time: ufscustom.start_time,
                opcode: ufscustom.opcode.clone(),
                value: LatencyValue::F64(ufscustom.ctod),
            })
            .collect::<Vec<_>>(),
        _ => return Err(format!("Invalid column: {}", params.column)),
    };

    // ì´ë¯¸ parquetì—ì„œ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì •ë ¬ ë¶ˆí•„ìš”

    // ê° opcodeë³„ ë ˆì´í„´ì‹œ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
    let mut latency_counts = std::collections::BTreeMap::new();
    let opcodes: std::collections::HashSet<String> = latency_stats
        .iter()
        .map(|stat| stat.opcode.clone())
        .collect();

    for opcode in opcodes {
        latency_counts.insert(opcode.clone(), initialize_ranges(&params.thresholds));
    }

    // ê° ë°ì´í„°ì˜ latencyì— ë”°ë¼ êµ¬ê°„ ì¹´ìš´íŠ¸ ì¦ê°€
    for stat in &latency_stats {
        let latency = stat.value.as_f64();
        let range_key = create_range_key(latency, &threshold_values, &params.thresholds);

        if let Some(opcode_map) = latency_counts.get_mut(&stat.opcode) {
            *opcode_map.entry(range_key).or_insert(0) += 1;
        }
    }

    // ë°±ë¶„ìœ„ìˆ˜ ë° í†µê³„ ê³„ì‚° (opcodeë³„ë¡œ ìˆ˜í–‰)
    let mut summary = BTreeMap::new();
    let mut opcode_values: HashMap<String, Vec<f64>> = HashMap::new();

    for stat in &latency_stats {
        let latency = stat.value.as_f64();
        opcode_values
            .entry(stat.opcode.clone())
            .or_insert_with(Vec::new)
            .push(latency);
    }

    for (opcode, mut values) in opcode_values {
        let stats = calculate_statistics(&mut values);
        summary.insert(opcode, stats);
    }

    let result = LatencyStats {
        latency_counts,
        summary: Some(summary),
    };

    // JSONìœ¼ë¡œ ì§ë ¬í™” í›„ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    serde_json::to_vec(&result).map_err(|e| format!("Failed to serialize latency stats: {}", e))
}

// UFSCUSTOM í¬ê¸° í†µê³„ í•¨ìˆ˜
pub async fn sizestats(params: UfscustomSizeStatsParams) -> Result<Vec<u8>, String> {
    // í•„í„°ë§ ì ìš©
    let filtered_ufscustom =
        filter_ufscustom_data(&params.logname, params.time_from, params.time_to, &params.zoom_column, params.col_from, params.col_to, None)?;

    // opcodeë³„ë¡œ size ë¶„í¬ ê³„ì‚°
    let mut opcode_stats: BTreeMap<String, BTreeMap<u32, usize>> = BTreeMap::new();
    let mut total_counts: BTreeMap<String, usize> = BTreeMap::new();

    for ufscustom in &filtered_ufscustom {
        *opcode_stats
            .entry(ufscustom.opcode.clone())
            .or_insert_with(BTreeMap::new)
            .entry(ufscustom.size)
            .or_insert(0) += 1;

        *total_counts
            .entry(ufscustom.opcode.clone())
            .or_insert(0) += 1;
    }

    let result = SizeStats {
        opcode_stats,
        total_counts,
    };

    // JSONìœ¼ë¡œ ì§ë ¬í™” í›„ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    serde_json::to_vec(&result).map_err(|e| format!("Failed to serialize size stats: {}", e))
}

// UFSCUSTOM ì—°ì†ì„± í†µê³„ í•¨ìˆ˜
pub async fn continuity_stats(
    logname: String,
    zoom_column: String,
    time_from: Option<f64>,
    time_to: Option<f64>,
    col_from: Option<f64>,
    col_to: Option<f64>,
) -> Result<Vec<u8>, String> {
    // í•„í„°ë§ ì ìš©
    let filtered_ufscustom = 
        filter_ufscustom_data(&logname, time_from, time_to, &zoom_column, col_from, col_to, None)?;

    // opcodeë³„ ì—°ì†ì„± í†µê³„ ìˆ˜ì§‘
    let mut op_stats: BTreeMap<String, ContinuityCount> = BTreeMap::new();
    let mut total_requests = 0;
    let mut total_continuous = 0;
    let mut total_bytes: u64 = 0;
    let mut continuous_bytes: u64 = 0;

    for ufscustom in &filtered_ufscustom {
        // opcodeë³„ í†µê³„ ì—…ë°ì´íŠ¸
        let stats = op_stats
            .entry(ufscustom.opcode.clone())
            .or_insert(ContinuityCount {
                continuous: 0,
                non_continuous: 0,
                ratio: 0.0,
                total_bytes: 0,
                continuous_bytes: 0,
                bytes_ratio: 0.0,
            });

        // UFSCUSTOMì˜ sizeëŠ” ì„¹í„° ìˆ˜ (512 bytes ë‹¨ìœ„)
        let bytes = ufscustom.size as u64 * 512; // 512 bytes per sector
        stats.total_bytes += bytes;
        total_bytes += bytes;

        if ufscustom.continuous {
            stats.continuous += 1;
            stats.continuous_bytes += bytes;
            total_continuous += 1;
            continuous_bytes += bytes;
        } else {
            stats.non_continuous += 1;
        }
        total_requests += 1;
    }

    // ë¹„ìœ¨ ê³„ì‚°
    for (_, stats) in op_stats.iter_mut() {
        let total = stats.continuous + stats.non_continuous;
        if total > 0 {
            stats.ratio = (stats.continuous as f64) / (total as f64) * 100.0;
            if stats.total_bytes > 0 {
                stats.bytes_ratio =
                    (stats.continuous_bytes as f64) / (stats.total_bytes as f64) * 100.0;
            }
        }
    }

    let overall_ratio = if total_requests > 0 {
        (total_continuous as f64) / (total_requests as f64) * 100.0
    } else {
        0.0
    };

    let bytes_ratio = if total_bytes > 0 {
        (continuous_bytes as f64) / (total_bytes as f64) * 100.0
    } else {
        0.0
    };

    let result = ContinuityStats {
        op_stats,
        total: TotalContinuity {
            total_requests,
            continuous_requests: total_continuous,
            overall_ratio,
            total_bytes,
            continuous_bytes,
            bytes_ratio,
        },
    };

    // JSONìœ¼ë¡œ ì§ë ¬í™” í›„ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    serde_json::to_vec(&result).map_err(|e| format!("Failed to serialize continuity stats: {}", e))
}

// UFSCUSTOM ì¢…í•© í†µê³„ í•¨ìˆ˜
pub async fn allstats(params: UfscustomAllStatsParams, thresholds: Vec<String>) -> Result<Vec<u8>, String> {
    // í•„í„°ë§ ì ìš© (ì „ì²´ í†µê³„ì—ì„œëŠ” ê°œë³„ í•¨ìˆ˜ì—ì„œ í•„í„°ë§í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¶ˆí•„ìš”)
    let _filtered_ufscustom =
        filter_ufscustom_data(&params.logname, params.time_from, params.time_to, &params.zoom_column, params.col_from, params.col_to, None)?;

    // dtoc í†µê³„ ê³„ì‚°
    let dtoc_params = UfscustomLatencyStatsParams {
        logname: params.logname.clone(),
        column: "dtoc".to_string(),
        zoom_column: params.zoom_column.clone(),
        time_from: params.time_from,
        time_to: params.time_to,
        col_from: params.col_from,
        col_to: params.col_to,
        thresholds: thresholds.clone(),
    };
    let dtoc_bytes = latencystats(dtoc_params).await?;
    let dtoc_stat: LatencyStats = serde_json::from_slice(&dtoc_bytes)
        .map_err(|e| format!("Failed to deserialize dtoc stats: {}", e))?;

    // ctod í†µê³„ ê³„ì‚°
    let ctod_params = UfscustomLatencyStatsParams {
        logname: params.logname.clone(),
        column: "ctod".to_string(),
        zoom_column: params.zoom_column.clone(),
        time_from: params.time_from,
        time_to: params.time_to,
        col_from: params.col_from,
        col_to: params.col_to,
        thresholds: thresholds.clone(),
    };
    let ctod_bytes = latencystats(ctod_params).await?;
    let ctod_stat: LatencyStats = serde_json::from_slice(&ctod_bytes)
        .map_err(|e| format!("Failed to deserialize ctod stats: {}", e))?;

    // ctoc í†µê³„ ê³„ì‚°
    let ctoc_params = UfscustomLatencyStatsParams {
        logname: params.logname.clone(),
        column: "ctoc".to_string(),
        zoom_column: params.zoom_column.clone(),
        time_from: params.time_from,
        time_to: params.time_to,
        col_from: params.col_from,
        col_to: params.col_to,
        thresholds: thresholds.clone(),
    };
    let ctoc_bytes = latencystats(ctoc_params).await?;
    let ctoc_stat: LatencyStats = serde_json::from_slice(&ctoc_bytes)
        .map_err(|e| format!("Failed to deserialize ctoc stats: {}", e))?;

    // í¬ê¸° í†µê³„ ê³„ì‚°
    let size_params = UfscustomSizeStatsParams {
        logname: params.logname.clone(),
        column: "size".to_string(),
        zoom_column: params.zoom_column.clone(),
        time_from: params.time_from,
        time_to: params.time_to,
        col_from: params.col_from,
        col_to: params.col_to,
    };
    let size_bytes = sizestats(size_params).await?;
    let size_counts: SizeStats = serde_json::from_slice(&size_bytes)
        .map_err(|e| format!("Failed to deserialize size stats: {}", e))?;

    // ì—°ì†ì„± í†µê³„ ê³„ì‚°
    let continuity_bytes = continuity_stats(
        params.logname.clone(),
        params.zoom_column.clone(),
        params.time_from,
        params.time_to,
        params.col_from,
        params.col_to,
    )
    .await?;
    let continuity: ContinuityStats = serde_json::from_slice(&continuity_bytes)
        .map_err(|e| format!("Failed to deserialize continuity stats: {}", e))?;

    // ì¢…í•© í†µê³„ ìƒì„±
    let all_stats = TraceStats {
        dtoc_stat,
        ctod_stat,
        ctoc_stat,
        size_counts,
        continuity,
    };

    // JSONìœ¼ë¡œ ì§ë ¬í™” í›„ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    serde_json::to_vec(&all_stats).map_err(|e| format!("Failed to serialize all stats: {}", e))
}
